{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from src.datasets.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 100 out of 3262.790816 chunks\n",
      "Written 200 out of 3262.790816 chunks\n",
      "Written 300 out of 3262.790816 chunks\n",
      "Written 400 out of 3262.790816 chunks\n",
      "Written 500 out of 3262.790816 chunks\n",
      "Written 600 out of 3262.790816 chunks\n",
      "Written 700 out of 3262.790816 chunks\n",
      "Written 800 out of 3262.790816 chunks\n",
      "Written 900 out of 3262.790816 chunks\n",
      "Written 1000 out of 3262.790816 chunks\n",
      "Written 1100 out of 3262.790816 chunks\n",
      "Written 1200 out of 3262.790816 chunks\n",
      "Written 1300 out of 3262.790816 chunks\n",
      "Written 1400 out of 3262.790816 chunks\n",
      "Written 1500 out of 3262.790816 chunks\n",
      "Written 1600 out of 3262.790816 chunks\n",
      "Written 1700 out of 3262.790816 chunks\n",
      "Written 1800 out of 3262.790816 chunks\n",
      "Written 1900 out of 3262.790816 chunks\n",
      "Written 2000 out of 3262.790816 chunks\n",
      "Written 2100 out of 3262.790816 chunks\n",
      "Written 2200 out of 3262.790816 chunks\n",
      "Written 2300 out of 3262.790816 chunks\n",
      "Written 2400 out of 3262.790816 chunks\n",
      "Written 2500 out of 3262.790816 chunks\n",
      "Written 2600 out of 3262.790816 chunks\n",
      "Written 2700 out of 3262.790816 chunks\n",
      "Written 2800 out of 3262.790816 chunks\n",
      "Written 2900 out of 3262.790816 chunks\n",
      "Written 3000 out of 3262.790816 chunks\n",
      "Written 3100 out of 3262.790816 chunks\n",
      "Written 3200 out of 3262.790816 chunks\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([790816])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay great, we have encodings registered in train. Now we need to build the basic prediction loop. Let's Karpathy this out. \n",
    "# Our context length will be 8, but we also want to maximize the amount of training data we have to learn on. \n",
    "# That means we don't have to predict next char given previous 8. Think about it as predict the next char given <= 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the context is tensor([17]) the target is 27\n",
      "When the context is tensor([17, 27]) the target is 14\n",
      "When the context is tensor([17, 27, 14]) the target is 14\n",
      "When the context is tensor([17, 27, 14, 14]) the target is 36\n",
      "When the context is tensor([17, 27, 14, 14, 36]) the target is 29\n",
      "When the context is tensor([17, 27, 14, 14, 36, 29]) the target is 18\n",
      "When the context is tensor([17, 27, 14, 14, 36, 29, 18]) the target is 22\n",
      "When the context is tensor([17, 27, 14, 14, 36, 29, 18, 22]) the target is 14\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "x = train[:context_length]\n",
    "y = train[1:context_length+1]\n",
    "for i in range(context_length):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(\"When the context is {} the target is {}\".format(context, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-medgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
